data_dir: 'data'
preprocessed_dir: 'data/preprocessed'
target_dir: 'data/save'
model_path: 'google/flan-t5-base'
model_size: 'base'
label_list:  ['positive', 'negative', 'neutral']
emb_dim: 300
output_channels: 100
speaker_emb_dims: 300
project_dims: 300
max_length: 300
batch_size: 64
epoch_size: 20
train_mode: random
filters: [3,4,5]
dropout: 0.5
shuffle: True
learning_rate: 1e-4
bert_lr: 2e-4
patience: 100
max_grad_norm: 1.0
warmup_proportion: 0.1
gradient_accumulation_steps: 1
adam_epsilon: 1e-8
warmup_steps: 0
weight_decay: 0.01
seed: 42

# Remote inference (Hugging Face Inference API) for Flan-T5
# Note: this mode does NOT support training; use for zero-shot/eval only.
use_hf_inference: false
hf_model_id: ''           # e.g. google/flan-t5-xxl (empty = model_path)
hf_api_key: ''            # prefer env: HF_API_KEY or HUGGINGFACEHUB_API_TOKEN
hf_timeout: 60
hf_max_new_tokens: 64

# RVISA (two-stage reasoning + verification) stage-2 defaults
rvisa_alpha: 0.3
rvisa_gamma: 0.3
rvisa_use_verification: true
rvisa_use_explanation: true
# Prompt style used for the explanation task input (should match the stage-1 generator)
rvisa_prompt_style: th-re  # th-re | th-ra | reasoning | zero-cot
